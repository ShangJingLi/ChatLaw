import os
import time
import threading
import binascii
import gradio as gr
import markdown
from transformers import AutoTokenizer
from funasr_onnx import Paraformer
from chatlaw.configuration import config
from chatlaw.client.utils.utils_ms import (
    heartbeat_client_ms,
    stream_from_server_ms,
)
from chatlaw.client.utils.common_utils import (
    recv_exact,
    render_mathml_from_latex,
    connection_acknowledgement,
    speech_to_text
)
from chatlaw.dataloader import download_resources
from launcher import get_resources_path

alive = True
stop_event = threading.Event()


def alive_flag():
    return alive

resource_path = get_resources_path()
download_resources(resource_type="tokenizer")
tokenizer_path = os.path.join(resource_path, "tokenizer").replace("\\", "/")
tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, local_files_only=True)

download_resources(resource_type="audio_model")
AUDIO_MODEL_DIR = os.path.join(resource_path, "audio_model").replace("\\", "/")
TARGET_SR = 16000
AUDIO_CACHE_DIR = os.path.join(get_resources_path(), "_asr_cache")  # è¯­éŸ³ä¸´æ—¶æ–‡ä»¶ç›®å½•
os.makedirs(AUDIO_CACHE_DIR, exist_ok=True)
audio_model = Paraformer(
    AUDIO_MODEL_DIR,
    batch_size=1,
    quantize=True,   # ä½¿ç”¨ model_quant.onnx
    device_id=-1     # CPU-only
)

def gradio_interface_fn(input_audio, input_text):
    """
    åŠŸèƒ½ï¼š
        Gradio çš„æ ¸å¿ƒå›è°ƒå‡½æ•°ï¼Œè´Ÿè´£ï¼š
        1. å¯åŠ¨ä¸æœåŠ¡å™¨çš„å¿ƒè·³ç›‘æ§ï¼›
        2. å°†ç”¨æˆ·è¾“å…¥å°è£…ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼ï¼ˆnumpy å¼ é‡ï¼‰ï¼›
        3. æ‰§è¡Œä¸€æ¬¡çŸ­è¿æ¥æ¡æ‰‹éªŒè¯æœåŠ¡å™¨æ˜¯å¦åœ¨çº¿ï¼›
        4. å»ºç«‹æ¨ç†è¿æ¥å¹¶é€šè¿‡æµå¼åè®®æŒç»­æ¥æ”¶æ¨¡å‹è¾“å‡ºï¼›
        5. å°†å¢é‡è¾“å‡ºæ¸²æŸ“ä¸º Markdown + MathMLï¼Œå¹¶é€æ­¥å‘é€åˆ°å‰ç«¯ï¼›
        6. å¤„ç†æ¨ç†ä¸­æ–­ï¼ˆSTOPï¼‰ä»¥åŠå¼‚å¸¸æƒ…å†µã€‚

        æœ¬å‡½æ•°ä¸ºä¸€ä¸ª Python generatorï¼Œæ¯æ¬¡ yield ä¼šæ¨åŠ¨ Gradio æ›´æ–°ç•Œé¢ã€‚

    Args:
        input_audio : ç”¨æˆ·å½•å…¥è¯­éŸ³ï¼Œå°†ä½œä¸ºé—®è¯¢å†…å®¹æˆ– promptã€‚
        input_text (str): ç”¨æˆ·åœ¨å‰ç«¯è¾“å…¥çš„è‡ªç„¶è¯­è¨€æ–‡æœ¬ã€‚

    Inputs:
        - **input_text**: ç”¨æˆ·è¾“å…¥å†…å®¹ã€‚
        - å…¨å±€ä¾èµ–ï¼š
            - **alive**: æ§åˆ¶å¿ƒè·³çº¿ç¨‹ç»§ç»­æ‰§è¡Œçš„æ ‡å¿—ã€‚
            - **stop_event**: ç”¨äºæ¨ç†ä¸­æ–­çš„äº‹ä»¶å¯¹è±¡ã€‚
            - **tokenizer**: ç”¨äºç”Ÿæˆæ¨¡å‹è¾“å…¥çš„ tokenizerã€‚
            - **heartbeat_client_ms**: å¿ƒè·³çº¿ç¨‹å‡½æ•°ã€‚
            - **connection_acknowledgement**: æµ‹è¯•çŸ­è¿æ˜¯å¦æˆåŠŸçš„å‡½æ•°ã€‚
            - **stream_from_server_ms**: æµå¼æ¨ç†æ¥æ”¶å™¨ã€‚
            - **render_mathml_from_latex**: å°† Markdown è¾“å‡ºä¸­çš„ LaTeX è½¬æ¢ä¸º MathMLã€‚
            - **markdown.markdown**: æ¸²æŸ“ Markdownã€‚

    Outputs:
        ä½œä¸ºä¸€ä¸ªç”Ÿæˆå™¨ (generator)ï¼š
            yield ä¸¤ä¸ªå€¼ï¼š(status_text, html_output)
            ç¤ºä¾‹ï¼š
                - ("ğŸŸ¡ æ­£åœ¨å»ºç«‹è¿æ¥...", "")
                - ("âŒ›ï¸ è¯­éŸ³å¤„ç†ä¸­...", "")
                - ("âŒ›ï¸ çŸ¥è¯†åº“æ£€ç´¢ä¸­...", "")
                - ("ğŸŸ¢ æ¨ç†ä¸­...", "<html>æ¸²æŸ“å†…å®¹</html>")
                - ("ğŸ›‘ æ¨ç†å·²ä¸­æ–­ã€‚", "<html>æœ€ç»ˆæ¸²æŸ“</html>")
                - ("âš ï¸ æ•°æ®æ¥æ”¶å¼‚å¸¸ï¼šxxx", "")
                - ("âœ… æ¨ç†å®Œæˆã€‚", "<html>æœ€ç»ˆæ¸²æŸ“</html>")

        è¿™äº›å€¼ä¼šé€æ­¥é€šè¿‡ Gradio è¾“å‡ºåˆ°ç•Œé¢ã€‚

    Raises:
        æœ¬å‡½æ•°ä¸å‘å¤–æŠ›å‡ºå¼‚å¸¸ã€‚
        è‹¥åœ¨è¿æ¥æˆ–æ¨ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œå°† yield `"âš ï¸ æ•°æ®æ¥æ”¶å¼‚å¸¸ï¼šxxx"` å¹¶ç»“æŸå‡½æ•°ã€‚
    """
    # ===== è¯­éŸ³ / æ–‡æœ¬ äºŒé€‰ä¸€æ ¡éªŒ =====
    has_audio = input_audio is not None
    has_text = input_text is not None and input_text.strip() != ""

    if not has_audio and not has_text:
        yield "âš ï¸ è¯·è¾“å…¥è¯­éŸ³æˆ–æ–‡æœ¬ï¼", ""
        return

    if has_audio and has_text:
        yield "âš ï¸ è¯·å‹¿åŒæ—¶è¾“å…¥è¯­éŸ³å’Œæ–‡æœ¬ï¼", ""
        return

    # åªæœ‰è¯­éŸ³è¾“å…¥ï¼šå…ˆåš ASR
    if has_audio:
        yield "âŒ›ï¸ è¯­éŸ³å¤„ç†ä¸­...", ""
        input_text = speech_to_text(
            audio=input_audio,
            audio_model=audio_model,
            audio_cache_dir=AUDIO_CACHE_DIR,
            target_sr=TARGET_SR
        )
    # åªæœ‰æ–‡æœ¬è¾“å…¥ï¼šç›´æ¥ä½¿ç”¨ input_text

    global alive
    alive = True
    stop_event.clear()

    # å¯åŠ¨å¿ƒè·³çº¿ç¨‹
    threading.Thread(
        target=heartbeat_client_ms,
        args=(
            config.SERVER_IP,
            config.HEARTBEAT_PORT,
            config.HB_INTERVAL,
            config.HB_TIMEOUT,
            alive_flag,
            stop_event,
            recv_exact,
        ),
        daemon=True
    ).start()

    try:
        start_time = time.time()
        yield "ğŸŸ¡ æ­£åœ¨å»ºç«‹è¿æ¥...", ""

        # â€”â€” æ„å»ºæ¨¡å‹è¾“å…¥ï¼ˆnp tensorï¼‰ â€”â€”
        messages = [{"role": "user", "content": input_text}]
        templated = tokenizer.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        model_inputs = tokenizer([templated], return_tensors="np")

        # â€”â€” è¿æ¥ç¡®è®¤ï¼ˆçŸ­è¿æ¥ï¼‰ â€”â€”
        detail, status = connection_acknowledgement(
            config.SERVER_IP,
            config.DATA_PORT,
            binascii.unhexlify(config.DATA_HANDSHAKE_REQ),
            binascii.unhexlify(config.DATA_HANDSHAKE_RESP),
            recv_exact,
            start_time
        )
        yield detail, ""

        if not status:
            alive = False
            return

        yield "âœ… å·²è¿æ¥æœåŠ¡å™¨ï¼Œå¼€å§‹æ¨ç†...", ""

        # â€”â€” æµå¼æ¥æ”¶ â€”â€”
        partial_md = ""

        for chunk in stream_from_server_ms(
            config.SERVER_IP,
            config.DATA_PORT,
            binascii.unhexlify(config.DATA_HANDSHAKE_REQ),
            binascii.unhexlify(config.DATA_HANDSHAKE_RESP),
            recv_exact,
            #alive_flag,      # âš ï¸ å½“å‰å‡½æ•°ç­¾åé‡Œæ²¡æœ‰è¿™ä¸ªå‚æ•°ï¼Œåé¢å¯ä»¥ä¸€èµ·æ”¹
            stop_event,
            model_inputs
        ):
            if stop_event.is_set():
                rendered = markdown.markdown(
                    partial_md, extensions=["fenced_code", "tables"]
                )
                yield "ğŸ›‘ æ¨ç†å·²ä¸­æ–­ã€‚", rendered
                break

            if chunk == "<END>":
                rendered = markdown.markdown(
                    partial_md, extensions=["fenced_code", "tables"]
                )
                html_math = render_mathml_from_latex(rendered)
                yield "âœ… æ¨ç†å®Œæˆã€‚", html_math
                break

            partial_md += chunk
            rendered = markdown.markdown(
                partial_md, extensions=["fenced_code", "tables"]
            )
            html_math = render_mathml_from_latex(rendered)
            yield "ğŸŸ¢ æ¨ç†ä¸­...", html_math

    except Exception as e:
        yield f"âš ï¸ æ•°æ®æ¥æ”¶å¼‚å¸¸ï¼š{e}", ""

    finally:
        # global alive
        alive = False
        time.sleep(0.5)


def stop_fn():
    stop_event.set()
    return "ğŸ›‘ å·²å‘é€åœæ­¢ä¿¡å·ç»™æœåŠ¡å™¨", ""


with gr.Blocks(
    title="Qwen æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆUI + æµå¼è¾“å‡ºï¼‰",
    css="""
        #model_output {
          border: 2px solid #ccc;
          border-radius: 10px;
          background-color: #fff;
          padding: 15px;
          box-shadow: 0 3px 10px rgba(0,0,0,0.1);
          height: 500px;
          overflow-y: auto;
        }
    """
) as demo:

    gr.Markdown("## ğŸ”— Qwen æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆMindNLPç‰ˆï¼‰")
    audio_inp = gr.Audio(
        sources=["microphone"],
        type="numpy",
        label="ä¸­æ–‡è¯­éŸ³è¾“å…¥ï¼ˆè¯·è¯´å®Œæ•´ä¸€å¥è¯ï¼‰"
    )

    text_inp = gr.Textbox(label="è¾“å…¥æ–‡æœ¬", lines=2, placeholder="è¯·è¾“å…¥å†…å®¹...")
    status_box = gr.Textbox(label="è¿æ¥ä¸çŠ¶æ€ä¿¡æ¯", interactive=False)

    with gr.Row():
        btn_send = gr.Button("ğŸš€ å‘é€åˆ°æœåŠ¡å™¨")
        btn_stop = gr.Button("ğŸ›‘ åœæ­¢æ¨ç†")

    output_box = gr.HTML(label="æ¨¡å‹è¾“å‡º", elem_id="model_output")

    btn_send.click(gradio_interface_fn, inputs=[audio_inp, text_inp], outputs=[status_box, output_box])
    btn_stop.click(stop_fn, inputs=None, outputs=[status_box, output_box])


if __name__ == "__main__":
    demo.queue()
    demo.launch(inbrowser=True)
