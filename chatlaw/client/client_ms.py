import time
import threading
import binascii

import gradio as gr
import markdown
from transformers import AutoTokenizer

from chatlaw.configuration import config

# MindNLP å·¥å…·å‡½æ•°
from chatlaw.client.utils.utils_ms import (
    heartbeat_client_ms,
    stream_from_server_ms,
)

from chatlaw.client.utils.common_utils import (
    recv_exact,
    render_mathml_from_latex,
    connection_acknowledgement,
)

# ============================
# å…¨å±€çŠ¶æ€ï¼ˆä¾› utils_ms è°ƒç”¨ï¼‰
# ============================
alive = True
stop_event = threading.Event()


def alive_flag():
    return alive


# ============================
# åŠ è½½ tokenizer
# ============================
model_name = "Qwen/Qwen3-4B-Instruct-2507"
tokenizer = AutoTokenizer.from_pretrained(model_name)


# ============================
# Gradio å›è°ƒå‡½æ•°
# ============================
def gradio_interface_fn(input_text):
    global alive
    alive = True
    stop_event.clear()

    # å¯åŠ¨å¿ƒè·³çº¿ç¨‹
    threading.Thread(
        target=heartbeat_client_ms,
        args=(
            config.SERVER_IP,
            config.HEARTBEAT_PORT,
            config.HB_INTERVAL,
            config.HB_TIMEOUT,
            alive_flag,
            stop_event,
            recv_exact,
        ),
        daemon=True
    ).start()

    try:
        start_time = time.time()
        yield "ğŸŸ¡ æ­£åœ¨å»ºç«‹è¿æ¥...", ""

        # â€”â€” æ„å»ºæ¨¡å‹è¾“å…¥ï¼ˆnp tensorï¼‰ â€”â€”
        messages = [{"role": "user", "content": input_text}]
        templated = tokenizer.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        model_inputs = tokenizer([templated], return_tensors="np")

        # â€”â€” è¿æ¥ç¡®è®¤ï¼ˆçŸ­è¿æ¥ï¼‰ â€”â€”
        detail, status = connection_acknowledgement(
            config.SERVER_IP,
            config.DATA_PORT,
            binascii.unhexlify(config.DATA_HANDSHAKE_REQ),
            binascii.unhexlify(config.DATA_HANDSHAKE_RESP),
            recv_exact,
            start_time
        )
        yield detail, ""

        if not status:
            alive = False
            return

        yield "âœ… å·²è¿æ¥æœåŠ¡å™¨ï¼Œå¼€å§‹æ¨ç†...", ""

        # â€”â€” æµå¼æ¥æ”¶ â€”â€”
        partial_md = ""

        for chunk in stream_from_server_ms(
            config.SERVER_IP,
            config.DATA_PORT,
            binascii.unhexlify(config.DATA_HANDSHAKE_REQ),
            binascii.unhexlify(config.DATA_HANDSHAKE_RESP),
            recv_exact,
            #alive_flag,      # âš ï¸ å½“å‰å‡½æ•°ç­¾åé‡Œæ²¡æœ‰è¿™ä¸ªå‚æ•°ï¼Œåé¢å¯ä»¥ä¸€èµ·æ”¹
            stop_event,
            model_inputs
        ):
            if stop_event.is_set():
                rendered = markdown.markdown(
                    partial_md, extensions=["fenced_code", "tables"]
                )
                yield "ğŸ›‘ æ¨ç†å·²ä¸­æ–­ã€‚", rendered
                break

            if chunk == "<END>":
                rendered = markdown.markdown(
                    partial_md, extensions=["fenced_code", "tables"]
                )
                html_math = render_mathml_from_latex(rendered)
                yield "âœ… æ¨ç†å®Œæˆã€‚", html_math
                break

            partial_md += chunk
            rendered = markdown.markdown(
                partial_md, extensions=["fenced_code", "tables"]
            )
            html_math = render_mathml_from_latex(rendered)
            yield "ğŸŸ¢ æ¨ç†ä¸­...", html_math

    except Exception as e:
        yield f"âš ï¸ æ•°æ®æ¥æ”¶å¼‚å¸¸ï¼š{e}", ""

    finally:
        # global alive
        alive = False
        time.sleep(0.5)


# ============================
# åœæ­¢å›è°ƒ
# ============================
def stop_fn():
    stop_event.set()
    return "ğŸ›‘ å·²å‘é€åœæ­¢ä¿¡å·ç»™æœåŠ¡å™¨", ""


# ============================
# Gradio UI
# ============================
with gr.Blocks(
    title="Qwen æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆUI + æµå¼è¾“å‡ºï¼‰",
    css="""
        #model_output {
          border: 2px solid #ccc;
          border-radius: 10px;
          background-color: #fff;
          padding: 15px;
          box-shadow: 0 3px 10px rgba(0,0,0,0.1);
          height: 500px;
          overflow-y: auto;
        }
    """
) as demo:

    gr.Markdown("## ğŸ”— Qwen æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆMindNLPç‰ˆï¼‰")

    inp = gr.Textbox(label="è¾“å…¥æ–‡æœ¬", lines=2, placeholder="è¯·è¾“å…¥å†…å®¹...")
    status_box = gr.Textbox(label="è¿æ¥ä¸çŠ¶æ€ä¿¡æ¯", interactive=False)

    with gr.Row():
        btn_send = gr.Button("ğŸš€ å‘é€åˆ°æœåŠ¡å™¨")
        btn_stop = gr.Button("ğŸ›‘ åœæ­¢æ¨ç†")

    output_box = gr.HTML(label="æ¨¡å‹è¾“å‡º", elem_id="model_output")

    btn_send.click(gradio_interface_fn, inputs=inp, outputs=[status_box, output_box])
    btn_stop.click(stop_fn, inputs=None, outputs=[status_box, output_box])


if __name__ == "__main__":
    demo.queue()
    demo.launch()
