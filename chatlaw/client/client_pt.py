import os
import time
import threading
import binascii
import gradio as gr
import markdown
from transformers import AutoTokenizer
from funasr_onnx import Paraformer
from chatlaw.client.utils.common_utils import (recv_exact,
                                               render_mathml_from_latex,
                                               connection_acknowledgement,
                                               speech_to_text)
from chatlaw.configuration import config
from chatlaw.client.utils.utils_pt import (
    heartbeat_client,
    stream_from_server,
)
from chatlaw.dataloader import download_resources
from launcher import get_resources_path


# ========== å…¨å±€çŠ¶æ€ ==========
alive = True                 # æ•°æ®æµæ˜¯å¦ç»§ç»­
stop_event = threading.Event()  # STOP ä¿¡å·

def alive_flag():
    return alive

resource_path = get_resources_path()
download_resources(resource_type="tokenizer")
tokenizer_path = os.path.join(resource_path, "tokenizer").replace("\\", "/")
tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, local_files_only=True)

download_resources(resource_type="audio_model")
AUDIO_MODEL_DIR = os.path.join(resource_path, "audio_model").replace("\\", "/")
TARGET_SR = 16000
AUDIO_CACHE_DIR = os.path.join(get_resources_path(), "_asr_cache")  # è¯­éŸ³ä¸´æ—¶æ–‡ä»¶ç›®å½•
os.makedirs(AUDIO_CACHE_DIR, exist_ok=True)
audio_model = Paraformer(
    AUDIO_MODEL_DIR,
    batch_size=1,
    quantize=True,   # ä½¿ç”¨ model_quant.onnx
    device_id=-1     # CPU-only
)


def gradio_interface_fn(input_audio, input_text):
    """
    åŠŸèƒ½ï¼š
        Gradio çš„æ ¸å¿ƒå›è°ƒç”Ÿæˆå™¨å‡½æ•°ï¼Œæ¯æ¬¡ç”¨æˆ·ç‚¹å‡»â€œå‘é€â€æŒ‰é’®éƒ½ä¼šè§¦å‘ä¸€æ¬¡æ–°çš„æ¨ç†æµç¨‹ã€‚
        æœ¬å‡½æ•°è´Ÿè´£ï¼š
        1. å¯åŠ¨å¿ƒè·³çº¿ç¨‹ï¼Œç¡®ä¿æœåŠ¡å™¨è¿æ¥å­˜æ´»ï¼›
        2. å°†ç”¨æˆ·è¾“å…¥å°è£…ä¸ºæ¨¡å‹å¯å¤„ç†çš„ promptï¼›
        3. é€šè¿‡ä¸€æ¬¡çŸ­è¿æ¥æ£€æµ‹æœåŠ¡å™¨æ˜¯å¦å¯ç”¨ï¼›
        4. ä¸æœåŠ¡å™¨å»ºç«‹æ•°æ®è¿æ¥å¹¶è¿›è¡Œæµå¼æ¨ç†æ¥æ”¶ï¼›
        5. åœ¨æ¨ç†è¿‡ç¨‹ä¸­æŒç»­å‘å‰ç«¯ UI å‘é€å¢é‡æ¸²æŸ“ç»“æœï¼›
        6. åœ¨ STOP ä¸­æ–­ã€é”™è¯¯ã€æˆ–æœåŠ¡å™¨è¿”å› <END> æ—¶è¿›è¡Œæ”¶å°¾å¤„ç†ã€‚

        è¯¥å‡½æ•°æ˜¯ä¸€ä¸ª Python generatorï¼Œæ¯ä¸€æ¬¡ `yield` éƒ½ä¼šä¿ƒä½¿ Gradio ç«‹å³æ›´æ–°ç•Œé¢ï¼Œ
        ç”¨äºå®ç°å®æ—¶æµå¼è¾“å‡ºæ•ˆæœã€‚

    Args:
        input_audio : ç”¨æˆ·å½•å…¥è¯­éŸ³ï¼Œå°†ä½œä¸ºé—®è¯¢å†…å®¹æˆ– promptã€‚
        input_text (str): ç”¨æˆ·è¾“å…¥çš„è‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼Œå°†ä½œä¸ºé—®è¯¢å†…å®¹æˆ– promptã€‚

    Inputs:
        - **input_text**: å‰ç«¯ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬å†…å®¹ã€‚
        - **input_audio**: å‰ç«¯ç”¨æˆ·è¾“å…¥çš„è¯­éŸ³å†…å®¹ã€‚
        - å…¨å±€ä¾èµ–ï¼š
            - **alive** (bool): æ§åˆ¶å¿ƒè·³çº¿ç¨‹ç»§ç»­è¿è¡Œçš„æ ‡å¿—ã€‚
            - **stop_event** (Event): å‰ç«¯ç”¨äºåœæ­¢æ¨ç†çš„äº‹ä»¶ä¿¡å·ã€‚
            - **tokenizer**: æ„é€ æ¨¡å‹è¾“å…¥çš„ tokenizerã€‚
            - **heartbeat_client**: å¿ƒè·³çº¿ç¨‹å‡½æ•°ï¼Œç”¨äºç»´æŠ¤ä¸æœåŠ¡å™¨çš„å­˜æ´»æ€§æ£€æµ‹ã€‚
            - **connection_acknowledgement**: ç”¨äºçŸ­è¿æ¥æµ‹è¯•æœåŠ¡å™¨æ˜¯å¦åœ¨çº¿ã€‚
            - **stream_from_server**: æµå¼æ¨ç†æ•°æ®æ¥æ”¶å™¨ã€‚
            - **render_mathml_from_latex**: å°† Markdown ä¸­çš„å…¬å¼è½¬æ¢ä¸º MathMLã€‚
            - **markdown.markdown**: æ¸²æŸ“ Markdown æ–‡æœ¬ã€‚

    Outputs:
        ä½œä¸ºä¸€ä¸ªç”Ÿæˆå™¨ï¼ˆgeneratorï¼‰ï¼Œæœ¬å‡½æ•°å¤šæ¬¡ yieldï¼š
            (çŠ¶æ€æ–‡æœ¬, HTMLæ¸²æŸ“å†…å®¹)
        ç¤ºä¾‹ï¼š
            - ("ğŸŸ¡ æ­£åœ¨å»ºç«‹è¿æ¥...", "")
            - ("âŒ›ï¸ è¯­éŸ³å¤„ç†ä¸­...", "")
            - ("âŒ›ï¸ çŸ¥è¯†åº“æ£€ç´¢ä¸­...", "")
            - ("ğŸŸ¢ æ¨ç†ä¸­...", "<html>æ¸²æŸ“å†…å®¹</html>")
            - ("ğŸ›‘ æ¨ç†å·²ä¸­æ–­ã€‚", "<html>æœ€ç»ˆæ¸²æŸ“</html>")
            - ("âš ï¸ æ•°æ®æ¥æ”¶å¼‚å¸¸ï¼šxxx", "")
            - ("âœ… æ¨ç†å®Œæˆã€‚", "<html>æœ€ç»ˆæ¸²æŸ“</html>")

        è¿™äº›å€¼å°†è¢« Gradio è‡ªåŠ¨é€æ®µæ¸²æŸ“åˆ° UI ä¸­ï¼Œå®ç°å®æ—¶è¾“å‡ºä½“éªŒã€‚

    Raises:
        æœ¬å‡½æ•°ä¸å‘å¤–æŠ›å‡ºå¼‚å¸¸ã€‚
        æ‰€æœ‰è¿æ¥å¼‚å¸¸ã€æ¨ç†å¼‚å¸¸ç­‰å‡ä»¥ yield çš„å½¢å¼è¿”å›ç»™å‰ç«¯ï¼Œ
        æ ¼å¼ä¸ºï¼š"âš ï¸ æ•°æ®æ¥æ”¶å¼‚å¸¸ï¼šxxx"ã€‚
    """
    # ===== è¯­éŸ³ / æ–‡æœ¬ äºŒé€‰ä¸€æ ¡éªŒ =====
    has_audio = input_audio is not None
    has_text = input_text is not None and input_text.strip() != ""

    if not has_audio and not has_text:
        yield "âš ï¸ è¯·è¾“å…¥è¯­éŸ³æˆ–æ–‡æœ¬ï¼", ""
        return

    if has_audio and has_text:
        yield "âš ï¸ è¯·å‹¿åŒæ—¶è¾“å…¥è¯­éŸ³å’Œæ–‡æœ¬ï¼", ""
        return

    # åªæœ‰è¯­éŸ³è¾“å…¥ï¼šå…ˆåš ASR
    if has_audio:
        yield "âŒ›ï¸ è¯­éŸ³å¤„ç†ä¸­...", ""
        input_text = speech_to_text(
            audio=input_audio,
            audio_model=audio_model,
            audio_cache_dir=AUDIO_CACHE_DIR,
            target_sr=TARGET_SR
        )
    # åªæœ‰æ–‡æœ¬è¾“å…¥ï¼šç›´æ¥ä½¿ç”¨ input_text

    global alive
    alive = True
    stop_event.clear()

    # å¯åŠ¨å¿ƒè·³
    threading.Thread(
        target=heartbeat_client,
        args=(
            config.SERVER_IP,
            config.HEARTBEAT_PORT,
            config.HB_INTERVAL,
            config.HB_TIMEOUT,
            alive_flag,
            stop_event,
            recv_exact,
        ),
        daemon=True
    ).start()

    try:
        start_time = time.time()
        yield "ğŸŸ¡ æ­£åœ¨å»ºç«‹è¿æ¥...", ""

        # ---- æ„é€ æ¨¡å‹è¾“å…¥ ----
        messages = [{"role": "user", "content": input_text}]
        templated = tokenizer.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        model_inputs = tokenizer([templated], return_tensors="pt")

        # ---- è¿æ¥æ£€æµ‹ï¼ˆçŸ­è¿æ¥ï¼‰ ----
        detail, status = connection_acknowledgement(
            config.SERVER_IP,
            config.DATA_PORT,
            binascii.unhexlify(config.DATA_HANDSHAKE_REQ),
            binascii.unhexlify(config.DATA_HANDSHAKE_RESP),
            recv_exact,
            start_time
        )
        yield detail, ""

        if not status:
            alive = False
            return

        yield "âœ… å·²è¿æ¥æœåŠ¡å™¨ï¼Œå¼€å§‹æ¨ç†...", ""

        # ========== æµå¼æ¥æ”¶ ==========
        partial_md = ""

        for chunk in stream_from_server(
            config.SERVER_IP,
            config.DATA_PORT,
            binascii.unhexlify(config.DATA_HANDSHAKE_REQ),
            binascii.unhexlify(config.DATA_HANDSHAKE_RESP),
            recv_exact,
            alive_flag,
            stop_event,
            model_inputs
        ):
            # ---- é”™è¯¯æƒ…å†µ ----
            if isinstance(chunk, str) and chunk.startswith("[ClientError]"):
                yield f"âš ï¸ æ•°æ®æ¥æ”¶å¼‚å¸¸ï¼š{chunk}", ""
                break

            # ---- æœåŠ¡ç«¯ç»“æŸ ----
            if chunk == "<END>":
                rendered = markdown.markdown(
                    partial_md, extensions=["fenced_code", "tables"]
                )
                html = render_mathml_from_latex(rendered)

                if stop_event.is_set():
                    yield "ğŸ›‘ æ¨ç†å·²ä¸­æ–­ã€‚", f"<div>{html}</div>"
                else:
                    yield "âœ… æ¨ç†å®Œæˆã€‚", f"<div>{html}</div>"
                break

            # ---- å¢é‡ç”Ÿæˆ ----
            partial_md += chunk
            rendered = markdown.markdown(
                partial_md, extensions=["fenced_code", "tables"]
            )
            html = render_mathml_from_latex(rendered)

            if stop_event.is_set():
                yield "ğŸŸ¡ ç­‰å¾…æœåŠ¡å™¨åœæ­¢æ¨ç†...", f"<div>{html}</div>"
            else:
                yield "ğŸŸ¢ æ¨ç†ä¸­...", f"<div>{html}</div>"

    except Exception as e:
        yield f"âš ï¸ æ•°æ®æ¥æ”¶å¼‚å¸¸ï¼š{e}", ""
        return

    finally:
        alive = False
        time.sleep(0.5)  # ç»™å¿ƒè·³çº¿ç¨‹ä¸€ç‚¹æ—¶é—´é€€å‡º


def stop_fn():
    stop_event.set()
    return "ğŸ›‘ å·²å‘é€åœæ­¢ä¿¡å·åˆ°æœåŠ¡å™¨", ""


with gr.Blocks(
    title="Qwen æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆTransformers ç‰ˆï¼‰",
    css="""
        #model_output {
          border: 2px solid #ccc;
          border-radius: 10px;
          background-color: #fff;
          padding: 15px;
          box-shadow: 0 3px 10px rgba(0,0,0,0.1);
          height: 500px;
          overflow-y: auto;
        }
    """
) as demo:

    gr.Markdown("## ğŸ”— Qwen æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆTransformers ç‰ˆï¼‰")

    audio_inp = gr.Audio(
        sources=["microphone"],
        type="numpy",
        label="ä¸­æ–‡è¯­éŸ³è¾“å…¥ï¼ˆè¯·è¯´å®Œæ•´ä¸€å¥è¯ï¼‰"
    )
    text_inp = gr.Textbox(label="è¾“å…¥æ–‡æœ¬", lines=2, placeholder="è¯·è¾“å…¥å†…å®¹...")
    status_box = gr.Textbox(label="è¿æ¥ä¸çŠ¶æ€ä¿¡æ¯", interactive=False)

    with gr.Row():
        btn_send = gr.Button("ğŸš€ å‘é€åˆ°æœåŠ¡å™¨")
        btn_stop = gr.Button("ğŸ›‘ åœæ­¢æ¨ç†")

    output_box = gr.HTML(label="æ¨¡å‹è¾“å‡º", elem_id="model_output")

    btn_send.click(gradio_interface_fn, inputs=[audio_inp, text_inp], outputs=[status_box, output_box])
    btn_stop.click(stop_fn, inputs=None, outputs=[status_box, output_box])


if __name__ == "__main__":
    demo.launch(inbrowser=True)
