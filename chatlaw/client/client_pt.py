import os
import time
import threading
import binascii
import gradio as gr
import markdown
from transformers import AutoTokenizer
from chatlaw.client.utils.common_utils import (recv_exact,
                                               render_mathml_from_latex,
                                               connection_acknowledgement)
from chatlaw.configuration import config
from chatlaw.client.utils.utils_pt import (
    heartbeat_client,
    stream_from_server,
)
from chatlaw.dataloader import download_resources
from launcher import get_resources_path


# ========== å…¨å±€çŠ¶æ€ ==========
alive = True                 # æ•°æ®æµæ˜¯å¦ç»§ç»­
stop_event = threading.Event()  # STOP ä¿¡å·


def alive_flag():
    return alive


# ========== Tokenizer å‡†å¤‡ ==========
resource_path = get_resources_path()
model_name = "Qwen/Qwen3-4B-Instruct-2507"

if not os.path.exists(os.path.join(resource_path, "tokenizer")):
    download_resources(resource_type="tokenizer")

tokenizer_path = os.path.join(resource_path, "tokenizer").replace("\\", "/")
tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, local_files_only=True)


# ============================
# Gradio å›è°ƒå‡½æ•°
# ============================
def gradio_interface_fn(input_text):
    """
    æ¯æ¬¡ç‚¹å‡»â€œå‘é€â€éƒ½ä¼šè¿›å…¥ä¸€æ¬¡ç”Ÿæˆå™¨åºåˆ—ã€‚
    """
    global alive
    alive = True
    stop_event.clear()

    # å¯åŠ¨å¿ƒè·³
    threading.Thread(
        target=heartbeat_client,
        args=(
            config.SERVER_IP,
            config.HEARTBEAT_PORT,
            config.HB_INTERVAL,
            config.HB_TIMEOUT,
            alive_flag,
            stop_event,
            recv_exact,
        ),
        daemon=True
    ).start()

    try:
        start_time = time.time()
        yield "ğŸŸ¡ æ­£åœ¨å»ºç«‹è¿æ¥...", ""

        # ---- æ„é€ æ¨¡å‹è¾“å…¥ ----
        messages = [{"role": "user", "content": input_text}]
        templated = tokenizer.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        model_inputs = tokenizer([templated], return_tensors="pt")

        # ---- è¿æ¥æ£€æµ‹ï¼ˆçŸ­è¿æ¥ï¼‰ ----
        detail, status = connection_acknowledgement(
            config.SERVER_IP,
            config.DATA_PORT,
            binascii.unhexlify(config.DATA_HANDSHAKE_REQ),
            binascii.unhexlify(config.DATA_HANDSHAKE_RESP),
            recv_exact,
            start_time
        )
        yield detail, ""

        if not status:
            alive = False
            return

        yield "âœ… å·²è¿æ¥æœåŠ¡å™¨ï¼Œå¼€å§‹æ¨ç†...", ""

        # ========== æµå¼æ¥æ”¶ ==========
        partial_md = ""

        for chunk in stream_from_server(
            config.SERVER_IP,
            config.DATA_PORT,
            binascii.unhexlify(config.DATA_HANDSHAKE_REQ),
            binascii.unhexlify(config.DATA_HANDSHAKE_RESP),
            recv_exact,
            alive_flag,
            stop_event,
            model_inputs
        ):
            # ---- é”™è¯¯æƒ…å†µ ----
            if isinstance(chunk, str) and chunk.startswith("[ClientError]"):
                yield f"âš ï¸ æ•°æ®æ¥æ”¶å¼‚å¸¸ï¼š{chunk}", ""
                break

            # ---- æœåŠ¡ç«¯ç»“æŸ ----
            if chunk == "<END>":
                rendered = markdown.markdown(
                    partial_md, extensions=["fenced_code", "tables"]
                )
                html = render_mathml_from_latex(rendered)

                if stop_event.is_set():
                    yield "ğŸ›‘ æ¨ç†å·²ä¸­æ–­ã€‚", f"<div>{html}</div>"
                else:
                    yield "âœ… æ¨ç†å®Œæˆã€‚", f"<div>{html}</div>"
                break

            # ---- å¢é‡ç”Ÿæˆ ----
            partial_md += chunk
            rendered = markdown.markdown(
                partial_md, extensions=["fenced_code", "tables"]
            )
            html = render_mathml_from_latex(rendered)

            if stop_event.is_set():
                yield "ğŸŸ¡ ç­‰å¾…æœåŠ¡å™¨åœæ­¢æ¨ç†...", f"<div>{html}</div>"
            else:
                yield "ğŸŸ¢ æ¨ç†ä¸­...", f"<div>{html}</div>"

    except Exception as e:
        yield f"âš ï¸ æ•°æ®æ¥æ”¶å¼‚å¸¸ï¼š{e}", ""

    finally:
        alive = False
        time.sleep(0.5)  # ç»™å¿ƒè·³çº¿ç¨‹ä¸€ç‚¹æ—¶é—´é€€å‡º


# ============================
# åœæ­¢æŒ‰é’®
# ============================
def stop_fn():
    stop_event.set()
    return "ğŸ›‘ å·²å‘é€åœæ­¢ä¿¡å·åˆ°æœåŠ¡å™¨", ""


# ============================
# Gradio UI
# ============================
with gr.Blocks(
    title="Qwen æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆTransformers ç‰ˆï¼‰",
    css="""
        #model_output {
          border: 2px solid #ccc;
          border-radius: 10px;
          background-color: #fff;
          padding: 15px;
          box-shadow: 0 3px 10px rgba(0,0,0,0.1);
          height: 500px;
          overflow-y: auto;
        }
    """
) as demo:

    gr.Markdown("## ğŸ”— Qwen æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆTransformers ç‰ˆï¼‰")

    inp = gr.Textbox(label="è¾“å…¥æ–‡æœ¬", lines=2, placeholder="è¯·è¾“å…¥å†…å®¹...")
    status_box = gr.Textbox(label="è¿æ¥ä¸çŠ¶æ€ä¿¡æ¯", interactive=False)

    with gr.Row():
        btn_send = gr.Button("ğŸš€ å‘é€åˆ°æœåŠ¡å™¨")
        btn_stop = gr.Button("ğŸ›‘ åœæ­¢æ¨ç†")

    output_box = gr.HTML(label="æ¨¡å‹è¾“å‡º", elem_id="model_output")

    btn_send.click(gradio_interface_fn, inputs=inp, outputs=[status_box, output_box])
    btn_stop.click(stop_fn, inputs=None, outputs=[status_box, output_box])


if __name__ == "__main__":
    demo.queue()
    demo.launch()
